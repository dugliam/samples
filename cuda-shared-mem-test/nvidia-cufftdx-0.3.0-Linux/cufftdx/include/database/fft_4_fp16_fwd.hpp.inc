#ifndef CUFFTDX_FFT_4_FP16_FWD_PTX_HPP
#define CUFFTDX_FFT_4_FP16_FWD_PTX_HPP



template<> __forceinline__ __device__ void cufftdx_private_function<790, __half2, 1>(cufftdx::detail::complex<__half2> *rmem, void *smem){

asm volatile ("{\n\t"
    ".reg .b32 r<51>;\n\t"
    ".reg .b64 rd<2>;\n\t"
    "{\n\t"
    "add.f16x2 r1, %9, %13;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 r4, %10, %14;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 r7, %9, %13;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 r10, %10, %14;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 r13, %11, %15;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 r16, %12, %16;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 r19, %11, %15;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 r22, %12, %16;\n\t"
    "}\n\t"
    "{\n\t"
    "neg.f16x2 r25, r19;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 %0, r1, r13;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 %1, r4, r16;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 %4, r1, r13;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 %5, r4, r16;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 %2, r7, r22;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 %3, r10, r25;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 %6, r7, r22;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 %7, r10, r25;\n\t"
    "}\n\t"
    "}"
     : "=r"(__HALF2_TO_UI(rmem[0].x)), "=r"(__HALF2_TO_UI(rmem[0].y)), "=r"(__HALF2_TO_UI(rmem[1].x)), "=r"(__HALF2_TO_UI(rmem[1].y)), "=r"(__HALF2_TO_UI(rmem[2].x)), "=r"(__HALF2_TO_UI(rmem[2].y)), "=r"(__HALF2_TO_UI(rmem[3].x)), "=r"(__HALF2_TO_UI(rmem[3].y)): "l"(smem), "r"(__HALF2_TO_UI(rmem[0].x)), "r"(__HALF2_TO_UI(rmem[0].y)), "r"(__HALF2_TO_UI(rmem[1].x)), "r"(__HALF2_TO_UI(rmem[1].y)), "r"(__HALF2_TO_UI(rmem[2].x)), "r"(__HALF2_TO_UI(rmem[2].y)), "r"(__HALF2_TO_UI(rmem[3].x)), "r"(__HALF2_TO_UI(rmem[3].y)));
};




template<> __forceinline__ __device__ void cufftdx_private_function<791, __half2, 1>(cufftdx::detail::complex<__half2> *rmem, void *smem){

asm volatile ("{\n\t"
    ".reg .f32 f<5>;\n\t"
    ".reg .b32 r<84>;\n\t"
    ".reg .b64 rd<5>;\n\t"
    "mov.u32 r58, %tid.x;\n\t"
    "{\n\t"
    "add.f16x2 r7, %6, %8;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 r10, %7, %9;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 r13, %6, %8;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 r16, %7, %9;\n\t"
    "}\n\t"
    "and.b32 r3, r58, 1;\n\t"
    "mul.wide.u32 rd2, r3, 4;\n\t"
    "mov.u64 rd3, %5;\n\t"
    "add.s64 rd4, rd3, rd2;\n\t"
    "ld.global.u32 r22, [rd4];\n\t"
    "{\n\t"
    ".reg .f16 low, high;\n\t"
    "mov.b32 {low, high}, r22;\n\t"
    "mov.b32 r21, {low, low};\n\t"
    "}\n\t"
    "{\n\t"
    ".reg .f16 low, high;\n\t"
    "mov.b32 {low, high}, r22;\n\t"
    "mov.b32 r23, {high, high};\n\t"
    "}\n\t"
    "{\n\t"
    "mul.f16x2 r25, r16, r23;\n\t"
    "}\n\t"
    "{\n\t"
    "neg.f16x2 r28, r25;\n\t"
    "}\n\t"
    "{\n\t"
    "fma.rn.f16x2 r30, r13, r21, r28;\n\t"
    "}\n\t"
    "{\n\t"
    "mul.f16x2 r34, r13, r23;\n\t"
    "}\n\t"
    "{\n\t"
    "fma.rn.f16x2 r37, r16, r21, r34;\n\t"
    "}\n\t"
    "mov.u32 r59, %tid.y;\n\t"
    "shl.b32 r60, r59, 2;\n\t"
    "shl.b32 r61, r58, 1;\n\t"
    "and.b32 r62, r61, -4;\n\t"
    "add.s32 r6, r62, r60;\n\t"
    "barrier.sync 0;\n\t"
    "shl.b32 r63, r3, 1;\n\t"
    "add.s32 r64, r63, r6;\n\t"
    "shl.b32 r65, r64, 3;\n\t"
    "{\n\t"
    ".reg .u64 wide1;\n\t"
    ".reg .u32 narrow1;\n\t"
    "mov.u64 wide1, %4;\n\t"
    "cvt.u32.u64 narrow1, wide1;\n\t"
    "cvta.to.shared.u32 r66, narrow1;\n\t"
    "}\n\t"
    "add.s32 r67, r66, r65;\n\t"
    "st.shared.u32 [r67], r7;\n\t"
    "st.shared.u32 [r67+4], r10;\n\t"
    "st.shared.u32 [r67+8], r30;\n\t"
    "st.shared.u32 [r67+12], r37;\n\t"
    "barrier.sync 0;\n\t"
    "add.s32 r80, r3, r6;\n\t"
    "shl.b32 r81, r80, 3;\n\t"
    "add.s32 r83, r66, r81;\n\t"
    "ld.shared.u32 r69, [r83];\n\t"
    "ld.shared.u32 r72, [r83+4];\n\t"
    "ld.shared.u32 r70, [r83+16];\n\t"
    "ld.shared.u32 r73, [r83+20];\n\t"
    "{\n\t"
    "add.f16x2 %0, r69, r70;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 %1, r72, r73;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 %2, r69, r70;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 %3, r72, r73;\n\t"
    "}\n\t"
    "}"
     : "=r"(__HALF2_TO_UI(rmem[0].x)), "=r"(__HALF2_TO_UI(rmem[0].y)), "=r"(__HALF2_TO_UI(rmem[1].x)), "=r"(__HALF2_TO_UI(rmem[1].y)): "l"(smem), "l"(lut_hp_2_4), "r"(__HALF2_TO_UI(rmem[0].x)), "r"(__HALF2_TO_UI(rmem[0].y)), "r"(__HALF2_TO_UI(rmem[1].x)), "r"(__HALF2_TO_UI(rmem[1].y)));
};




template<> __forceinline__ __device__ void cufftdx_private_function<792, __half2, 1>(cufftdx::detail::complex<__half2> *rmem, void *smem){

asm volatile ("{\n\t"
    ".reg .f32 f<5>;\n\t"
    ".reg .b32 r<83>;\n\t"
    ".reg .b64 rd<5>;\n\t"
    "mov.u32 r63, %tid.y;\n\t"
    "mov.u32 r64, %tid.x;\n\t"
    "{\n\t"
    "add.f16x2 r12, %6, %8;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 r15, %7, %9;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 r18, %6, %8;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 r21, %7, %9;\n\t"
    "}\n\t"
    "and.b32 r3, r64, 1;\n\t"
    "shr.u32 r65, r64, 1;\n\t"
    "add.s32 r66, r65, r63;\n\t"
    "mul.wide.u32 rd2, r3, 4;\n\t"
    "mov.u64 rd3, %5;\n\t"
    "add.s64 rd4, rd3, rd2;\n\t"
    "ld.global.u32 r27, [rd4];\n\t"
    "{\n\t"
    ".reg .f16 low, high;\n\t"
    "mov.b32 {low, high}, r27;\n\t"
    "mov.b32 r26, {low, low};\n\t"
    "}\n\t"
    "{\n\t"
    ".reg .f16 low, high;\n\t"
    "mov.b32 {low, high}, r27;\n\t"
    "mov.b32 r28, {high, high};\n\t"
    "}\n\t"
    "{\n\t"
    "mul.f16x2 r30, r21, r28;\n\t"
    "}\n\t"
    "{\n\t"
    "neg.f16x2 r33, r30;\n\t"
    "}\n\t"
    "{\n\t"
    "fma.rn.f16x2 r35, r18, r26, r33;\n\t"
    "}\n\t"
    "{\n\t"
    "mul.f16x2 r39, r18, r28;\n\t"
    "}\n\t"
    "{\n\t"
    "fma.rn.f16x2 r42, r21, r26, r39;\n\t"
    "}\n\t"
    "shl.b32 r67, r66, 4;\n\t"
    "{\n\t"
    ".reg .u64 wide1;\n\t"
    ".reg .u32 narrow1;\n\t"
    "mov.u64 wide1, %4;\n\t"
    "cvt.u32.u64 narrow1, wide1;\n\t"
    "cvta.to.shared.u32 r68, narrow1;\n\t"
    "}\n\t"
    "add.s32 r6, r68, r67;\n\t"
    "barrier.sync 0;\n\t"
    "shl.b32 r69, r3, 3;\n\t"
    "add.s32 r8, r6, r69;\n\t"
    "st.shared.u32 [r8], r12;\n\t"
    "st.shared.u32 [r8+4], r35;\n\t"
    "barrier.sync 0;\n\t"
    "shl.b32 r70, r3, 2;\n\t"
    "add.s32 r9, r6, r70;\n\t"
    "ld.shared.u32 r10, [r9];\n\t"
    "ld.shared.u32 r11, [r9+8];\n\t"
    "barrier.sync 0;\n\t"
    "st.shared.u32 [r8], r15;\n\t"
    "st.shared.u32 [r8+4], r42;\n\t"
    "barrier.sync 0;\n\t"
    "ld.shared.u32 r75, [r9];\n\t"
    "ld.shared.u32 r76, [r9+8];\n\t"
    "{\n\t"
    "add.f16x2 %0, r10, r11;\n\t"
    "}\n\t"
    "{\n\t"
    "add.f16x2 %1, r75, r76;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 %2, r10, r11;\n\t"
    "}\n\t"
    "{\n\t"
    "sub.f16x2 %3, r75, r76;\n\t"
    "}\n\t"
    "}"
     : "=r"(__HALF2_TO_UI(rmem[0].x)), "=r"(__HALF2_TO_UI(rmem[0].y)), "=r"(__HALF2_TO_UI(rmem[1].x)), "=r"(__HALF2_TO_UI(rmem[1].y)): "l"(smem), "l"(lut_hp_2_4), "r"(__HALF2_TO_UI(rmem[0].x)), "r"(__HALF2_TO_UI(rmem[0].y)), "r"(__HALF2_TO_UI(rmem[1].x)), "r"(__HALF2_TO_UI(rmem[1].y)));
};


#endif
